# PE2
# 1 {{#system~}}
# 2 You are a helpful assistant.
# 3 {{~/system}}
# 4
# 5 {{#if instruction}}
# 6 {{#user~}}
# 7 Let 's read a blogpost on prompt engineering:
# 8 {{instruction}}
# 9 {{~/user}}
# 10 {{/ if } }
# 11
# 12 {{# user ~ } }
# 13 A prompt is a text paragraph that outlines the expected actions and instructs the model to generate a specific output. This prompt is concatenated with the input text, and the model then creates the required output.
# 14
# 15 In our collaboration , we'll work together to refine a prompt. The process consists of two main steps:
# 16
# 17 ## Step 1
# 18 I will provide you with the current prompt, how the prompt is concatenated with the input text ( i . e . , " full template"), along with {{batch_size}} example(s) that are associated with this prompt. Each examples contains the input, the reasoning process generated by the model when the prompt is attached, the final answer produced by the model, and the ground -truth label to the input. Your task is to analyze the examples, determining whether the existing prompt is decsribing the task reflected by these examples precisely, and suggest changes to the prompt.
# 19
# 20 ## Step 2
# 21 Next , you will carefully review your reasoning in step 1, integrate the insights to craft a new , optimized prompt. Optionally, the history of refinements made to this prompt from past sessions will be included. Some extra instructions (e.g., the number of words you can edit) will be provided too.
# 22 {{ ~/ user }}
# 23
# 24 {{# assistant ~ } }
# 25 Sure , I 'd be happy to help you with this prompt engineering problem .
# 26 Please provide me with the prompt engineering history , the current prompt , and the examples you have .
# 27 {{ ~/ assistant } }
# 28
# 29 {{# user ~ } }
# 30 ## Prompt
# 31 {{ prompt } }
# 32
# 33 ## Full Template
# 34 This describes how the prompt of interested is concatenated with the input text .
# 35 The prompt may appear before the input text , or after the input text .
# 36 Optionally the full template may contain other template information .
# 37
# 38 {{ full_prompt } }
# 39
# 40
# 41 ## Examples
# 42 {{ examples } }
# 43
# 44 ## Instructions
# 45 For some of these examples , the output does not match with the label . This may be due to the prompt being misleading or not describing the task precisely.
# 46
# 47 Please examine the example ( s ) carefully . Note that the ground - truth labels are __absolutely correct__ , but the prompts (task descriptions) may be incorrect and need modification. For each example, provide reasoning according to the following template:
# 48
# 49 ### Example <id >  29
# 50 Input : < input >
# 51 Output : < output >
# 52 Label : < label >
# 53 Is the output correct compared to the label : < yes or no , and your reasoning >
# 54 Is the output correctly following the given prompt : < yes or no , and your reasoning >
# 55 Is the prompt correctly describing the task shown by the input - label pair : < yes or no , and your reasoning >
# 56 To output the correct label , is it necessary to edit the prompt : < yes or no , and your reasoning >
# 57 If yes , provide detailed analysis and actionable suggestions to edit the prompt : < analysis and suggestions >
# 58 {{ ~/ user }}
# 59
# 60 {{# assistant ~ } }
# 61 {{ gen ' reasoning ' temperature = 0 } }
# 62 {{ ~/ assistant } }
# 63
# 64 {{# user ~ } }
# 65 Now please carefully review your reasoning in Step 1 and help with Step 2 : refining the prompt .
# 66
# 67 {{# if history } }
# 68 ## Prompt Refinement History from the Past
# 69 Note that higher accuracy means better . If some edits are useful in the past , it may be a good idea to make edits along the same direction.
# 70 {{ history } }
# 71 {{/ if } }
# 72
# 73 ## Current Prompt
# 74 {{ prompt } }
# 75
# 76 ## Instructions
# 77 {{# if step_size } }
# 78 * You are allowed to change up to { { step_size } } words in the original prompt .
# 79 {{/ if } }
# 80 {{# if max_tokens } }
# 81 * The total length of the prompt should be less than { { max_tokens } } words .
# 82 {{/ if } }
# 83 * Please help edit the prompt so that the updated prompt will not fail on these examples anymore .
# 84 * Reply with the prompt . Do not include other text .
# 85 {{ ~/ user }}
# 86
# 87 {{# assistant ~ } }
# 88 {{ gen ' new_prompt ' temperature = 0 . 7 max_tokens = 3 0 0 } }
# 89 {{ ~/ assistant } }
# 90
# 91 {{# if history } }
# 92 {{# user ~ } }
# 93 Now please summarize what changes you ' ve made to the prompt , in the following format . Make sure the summariy is concise and contains no more than 200 words.
# 94
# 95 " * At step { { timestamp } } , the prompt has limitations such as < summary of limitations >. Changes to the prompt include <summary of changes >."
# 96
# 97 Reply with the summarization . Do not include other text .
# 98 {{ ~/ user }}
# 99
# 100 {{# assistant ~ } }
# 101 {{ gen ' new_history ' temperature = 0 . 7 max_tokens = 2 0 0 } }
# 102 {{ ~/ assistant } }
# 103 {{/ if } }

from langchain_ollama import OllamaLLM
from langchain.prompts import PromptTemplate
from langchain.chains import LLMChain
from datetime import datetime

# Initialize Ollama model
model = OllamaLLM(model="llama3")  # or your preferred model

# Step 1: Analyze examples and generate reasoning
step1_template = PromptTemplate(
    input_variables=["prompt", "full_prompt", "examples"],
    template="""You are a helpful assistant. Let's analyze a prompt engineering task.

    ## Prompt
    {prompt}

    ## Full Template
    {full_prompt}

    ## Examples
    {examples}

    Please examine the examples carefully. For each example, provide reasoning using this template:
    ### Example <id>
    Input: <input>
    Output: <output>
    Label: <label>
    Is the output correct compared to the label: <yes/no, reasoning>
    Is the output correctly following the given prompt: <yes/no, reasoning>
    Is the prompt correctly describing the task: <yes/no, reasoning>
    To output the correct label, is it necessary to edit the prompt: <yes/no, reasoning>
    If yes, provide detailed analysis and suggestions: <analysis and suggestions>
    """,
    )

step1_chain = LLMChain(llm=model, prompt=step1_template)

# Step 2: Refine prompt
step2_template = PromptTemplate(
    input_variables=["reasoning", "prompt", "history", "step_size", "max_tokens"],
    template="""Review this reasoning from Step 1 and refine the prompt:

    {reasoning}

    ## Current Prompt
    {prompt}

    {'## Prompt Refinement History from the Past\\n' + history if history else ''}

    ## Instructions
    {'* You are allowed to change up to ' + str(step_size) + ' words' if step_size else ''}
    {'* The total length should be less than ' + str(max_tokens) + ' words' if max_tokens else ''}
    * Please edit the prompt to not fail on these examples anymore
    * Reply with only the refined prompt
    """,
)

step2_chain = LLMChain(llm=model, prompt=step2_template)

# Step 3: Summarize changes (if history is provided)
history_template = PromptTemplate(
    input_variables=["timestamp", "old_prompt", "new_prompt"],
    template="""Summarize the prompt changes concisely (max 200 words):

"* At step {timestamp}, the prompt has limitations such as <summary of limitations>. Changes to the prompt include <summary of changes>."

Reply with only the summarization.""",
)

history_chain = LLMChain(llm=model, prompt=history_template)


def refine_prompt(
    prompt: str,
    full_prompt: str,
    examples: str,
    history: str = None,
    step_size: int = None,
    max_tokens: int = None,
):
    # Step 1: Generate reasoning
    reasoning = step1_chain.run(
        {"prompt": prompt, "full_prompt": full_prompt, "examples": examples}
    )

    # Step 2: Generate new prompt
    new_prompt = step2_chain.run(
        {
            "reasoning": reasoning,
            "prompt": prompt,
            "history": history,
            "step_size": step_size,
            "max_tokens": max_tokens,
        }
    )

    # Step 3: Generate history summary if history is provided
    if history:
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        new_history = history_chain.run(
            {"timestamp": timestamp, "old_prompt": prompt, "new_prompt": new_prompt}
        )
        return reasoning, new_prompt, new_history

    return reasoning, new_prompt


# Example usage
if __name__ == "__main__":
    # Sample inputs
    current_prompt = "Classify the sentiment as positive or negative"
    full_prompt = "Classify the sentiment as positive or negative: {input}"
    examples = """Example 1
Input: I love this product
Output: negative
Label: positive
Example 2
Input: This is terrible
Output: negative
Label: negative"""

    # Run with no history
    reasoning, new_prompt = refine_prompt(
        prompt=current_prompt, full_prompt=full_prompt, examples=examples
    )

    print("Reasoning:\n", reasoning)
    print("New Prompt:\n", new_prompt)

    # Run with history and constraints
    history = "2025-02-20: Changed 'classify' to 'determine', accuracy improved from 70% to 85%"
    reasoning, new_prompt, new_history = refine_prompt(
        prompt=current_prompt,
        full_prompt=full_prompt,
        examples=examples,
        history=history,
        step_size=3,
        max_tokens=20,
    )

    print("Reasoning:\n", reasoning)
    print("New Prompt:\n", new_prompt)
    print("History Summary:\n", new_history)
